# -*- coding: utf-8 -*-
"""Functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jRqGBUuMuNn-veKwjPBBsFDn-ccBM8pa
"""

import csv
import cv2 as cv
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import math
import os
import seaborn as sns

CSV_FILE_PATH = "./dataset/dataset.csv"

def visualize_classes(dict):
  """
  function: display images that are already present in the dataset
  :param dict: dict['dataset_directory'] = 'C:/users/desktop/uploads/dataset.csv'
                dict['size'] = size of input image
  :return: class_ids, number of images in each class, one image from each class (all three are list)
  """
  x = []
  y = []
  with open(CSV_FILE_PATH, 'r') as f:
      reader = csv.reader(f)
      for row in reader:
          label = int(row[0])
          image = np.array([int(a) for a in row[1:]], dtype='uint8')
          image = image.reshape((dict['size'], dict['size']))
          x.append(image)
          y.append(label)

  class_ids = list(set(y))
  number_of_images = []
  images = []
  for i in class_ids:
      number_of_images.append(y.count(i))
      index = y.index(i)
      images.append(x[index])

  return class_ids, number_of_images, images

def upload_class(dict):
  """
  function: loading the class images uploaded by user
  :param dict: dict['existing_class'] = 'Y' or 'N'
              dict['path'] = list of names of images uploaded, e.g. ['images1.jpg', 'images2.jpg']
              dict['class_id'] = class id in which images are to be added
              dict['csv_file_path'] = 'C:/users/desktop/uploads/dataset.csv'
              dict['saved_images_directory'] = 'C:/users/desktop/uploads'
  :return:
  """
  with open(CSV_FILE_PATH, 'a') as f:
      writer = csv.writer(f)
      if dict['existing_class'] == 'Y':
          for i in dict['path']:
              img = cv.imread(os.path.join(dict['save_images_directory'], i))
              img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
              img = cv.resize(img, (32, 32))
              value = np.asarray(img, dtype=np.int)
              value = value.flatten()
              value = np.insert(value, 0, int(dict['class_id']), axis=0)
              writer.writerow(value)
      else:
          input_dict = {'dataset_directory' : CSV_FILE_PATH, 'size':32}
          class_ids, _, _ = visualize_classes(input_dict)
          next_class_id = len(class_ids)
          for i in dict['path']:
              img = cv.imread(os.path.join(dict['save_images_directory'], i))
              img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
              img = cv.resize(img, (32, 32))
              value = np.asarray(img, dtype=np.int)
              value = value.flatten()
              value = np.insert(value, 0, next_class_id, axis=0)
              writer.writerow(value)

  return "Uploaded Successfully"

# balancing functions
def list_to_dictionary(d):
  """
  function: merge two lists into a dictionary with keys as elements of 1st list and corresponding values as elements
            of 2nd list
  :param d: d['list1'] = 1st list
            d['list2'] = 2nd list
  :return: output_dictionary
  """
  output_dictionary = dict(zip(d['list1'], d['list2']))
  return output_dictionary

def augment_batch(d):
  """
  function: augments batch of images
  :param d: d['images'] = list of images
            d['input_aug'] = list of augmentations user specified
  :return: list of augmented images
  """
  images = d['images']
  input_aug = d['input_aug']
  for i in range(images.shape[0]):
      images[i] = augment(images[i], input_aug)  # Adarsh's augmentation function
  return images

def create_data_over(d):
  """
  function: oversample the dataset
  :param d: d['img_data'] = list of all images
            d['label_data'] = list of all labels
            d['i'] = class_id
            d['diff'] = number of images to be added
            d['input_aug'] = list of augmentations user specifies
  :return: list of oversampled images and labels
  """
  img_data = d['img_data']
  label_data = d['label_data']
  i = d['i']
  diff = d['diff']
  input_aug = d['input_aug']
  mask = [int(x) == i for x in label_data.tolist()]
  images1 = img_data[mask]
  del img_data
  label1 = label_data[mask]
  del label_data
  if diff < images1.shape[0]:
      idx = np.random.randint(images1.shape[0], size=diff)
      d_augment_batch = {'images': images1[idx], 'input_aug':input_aug}
      images2 = augment_batch(d_augment_batch)
      label2 = label1[idx]
      images = np.concatenate((images1, images2), axis=0)
      labels = np.concatenate((label1, label2), axis=0)
      return images, labels
  else:
      n = diff//images1.shape[0]
      diff = diff%images1.shape[0]
      idx = np.random.randint(images1.shape[0], size=diff)
      images2 = [images1]*n
      images2.append(images1[idx])
      images3 = np.concatenate(images2, axis=0)
      d_augment_batch = {'images': images3, 'input_aug': input_aug}
      images3 = augment_batch(d_augment_batch)
      label2 = [label1]*n
      label2.append(label1[idx])
      label3 = np.concatenate(label2, axis=0)
      images = np.concatenate((images1, images3), axis=0)
      labels = np.concatenate((label1, label3), axis=0)
      return images, labels

def create_data_under(d):
  """
  function: undersamples the dataset
  :param d: d['img_data'] = list of all images
            d['label_data'] = list of all labels
            d['i'] = class_id
            d['diff'] = number of images to be added
  :return: list of undersampled images and labels
  """
  img_data = d['img_data']
  label_data = d['label_data']
  i = d['i']
  diff = d['diff']
  mask = [int(x) == i for x in label_data.tolist()]
  images = img_data[mask]
  del img_data
  labels = label_data[mask]
  del label_data
  idx = np.random.randint(images.shape[0], size = labels.shape[0] - diff)
  images = images[idx]
  labels = labels[idx]
  return images, labels

def final_data(d):
  """
  function: returns balanced dataset
  :param d: d['class_ids'] = list of class ids specified by user
            d['number_of_images'] = list of number of images users wants in a class
            d['img_data'] = list of all images
            d['label_data'] = list of all labels
            d['input_aug'] = list of all augmentations specified by user
  :return: final list of augmented images and labels
  """
  d_list_to_dict = {'list1':d['class_ids'], 'list2':d['number_of_images']}
  var_num = list_to_dictionary(d_list_to_dict)
  img_data = d['img_data']
  label_data = d['label_data']

  unique, counts = np.unique(label_data, return_counts=True)
  num_per_class = dict(zip(unique, counts))

  images_lst = []
  labels_lst = []

  for i in range(len(unique)):
      diff = var_num[i] - num_per_class[i]
      if diff == 0:
          mask = [int(x) == i for x in label_data.tolist()]
          images = img_data[mask]
          labels = label_data[mask]
          images_lst.append(images)
          labels_lst.append(labels)
      elif diff > 0:
          d_create_data_over = {'img_data':d['img_data'], 'label_data':d['label_data'], 'i':i, 'diff':diff,
                                'input_aug':d['input_aug']}
          images, labels = create_data_over(d_create_data_over)
          images_lst.append(images)
          labels_lst.append(labels)
      elif diff < 0:
          d_create_data_under = {'img_data': d['img_data'], 'label_data': d['label_data'], 'i': i, 'diff': -diff}
          images, labels = create_data_under(d_create_data_under)
          images_lst.append(images)
          labels_lst.append(labels)

  del img_data, label_data

  X_data = np.concatenate(images_lst, axis=0)
  del images_lst
  Y_data = np.concatenate(labels_lst, axis=0)
  del labels_lst

  return X_data, Y_data

def visualize_image_distribution(d):
  """
  function: returns plot of data distribution in classes of dataset
  :param d: d['y'] = list of all labels
            d['datadir'] = path to data directory were plot needs to be saved
  :return: returns path of saved plot of distribution
  """
  y = d['y']
  category_names = [n for n in range(len(np.unique(y)))]
  label_num = []
  for i in category_names:
      num = sum(y == i)
      label_num.append(num)
  plt.figure(figsize=(20, 10))
  sns.barplot(category_names, label_num).set_title("Number of training images per category:")
  output_path = os.path.join(d['datadir'], 'image_data_distribution.png')
  plt.savefig(output_path)
  return output_path

def difficult_sam(d):
  """

  :param d: d['x'] =
            d['y'] =
            d['test_size'] =
            d['ypred'] =
  :return:
  """
  x = d['x']
  y = d['y']
  test_size = d['test_size']
  ypred = d['ypred']
  num = y.shape[0]
  num_test = int(num*test_size)
  num_train = num-num_test
  mask1 = y == ypred
  mask2 = y != ypred
  del ypred
  x1, y1 = x[mask1], y[mask1]
  x2, y2 = x[mask2], y[mask2]
  del mask1, mask2, x, y
  num_train = num_train-y2.shape[0]
  test_size = num_test/(num_test+num_train)
  x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=test_size)
  del x1, y1
  x_train, y_train = np.concatenate((x_train, x2), axis=0), np.concatenate((y_train, y2), axis=0)
  del x2, y2
  return x_train, x_test, y_train, y_test

def euc_mat(x):
  model = load_model("/content/yuvnish_tsr_model_v5.h5")
  layer_name = 'fc3'
  intermediate_layer = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
  x_vectors = intermediate_layer.predict(x)

  mat = cdist(x_vectors, x_vectors, metric='euclidean')

  del model
  del x_vectors
  return mat

def kennard_stone(x, y, test_size):
  num = y.shape[0]

  x_train = []
  y_train = []
  x_test = []
  y_test = []

  for i in range(len(np.unique(y))):
      mask = y == i
      class_num = sum(mask)
      cnum_test = int(class_num * test_size)
      cx = x[mask]
      cy = y[mask]
      eucl_mat = euc_mat(cx)

      select_p = []
      remain_p = [n for n in range(class_num)]
      first_2pts = np.unravel_index(np.argmax(eucl_mat), eucl_mat.shape)
      select_p.append(first_2pts[0])
      select_p.append(first_2pts[1])
      remain_p.remove(first_2pts[0])
      remain_p.remove(first_2pts[1])

      for _ in range(cnum_test - 2):
          select_distance = eucl_mat[select_p, :]
          min_distance = select_distance[:, remain_p]
          min_distance = np.min(min_distance, axis=0)
          max_min_distance = np.max(min_distance)
          points = np.argwhere(select_distance == max_min_distance)[:, 1].tolist()
          for point in points:
              if point in select_p:
                  pass
              else:
                  select_p.append(point)
                  remain_p.remove(point)
                  break

      del eucl_mat, select_distance

      xtrain, ytrain = cx[remain_p], cy[remain_p]
      xtest, ytest = cx[select_p], cy[select_p]

      del cx, cy

      x_train.append(xtrain)
      y_train.append(ytrain)
      x_test.append(xtest)
      y_test.append(ytest)

  del x, y

  xtrain = np.concatenate(x_train, axis=0)
  ytrain = np.concatenate(y_train, axis=0)
  xtest = np.concatenate(x_test, axis=0)
  ytest = np.concatenate(y_test, axis=0)

  del x_train, y_train, x_test, y_test

  return xtrain, xtest, ytrain, ytest

def split(sdict):
  name = sdict["name"]
  X_data = sdict["X_data"]
  Y_data = sdict["Y_data"]
  test_size = sdict["test_size"]
  Y_pred = sdict["Y_pred"]

  if name == "Normal":
      xtrain, xtest, ytrain, ytest = train_test_split(X_data, Y_data, test_size=test_size)
      return xtrain, xtest, ytrain, ytest
  elif name == "Stratified":
      xtrain, xtest, ytrain, ytest = train_test_split(X_data, Y_data, test_size=test_size, stratify=Y_data)
      return xtrain, xtest, ytrain, ytest
  elif name == "Difficult_samples":
      xtrain, xtest, ytrain, ytest = difficult_sam(X_data, Y_data, test_size=test_size, ypred=Y_pred)
      return xtrain, xtest, ytrain, ytest
  elif name == "kennard_stone":
      xtrain, xtest, ytrain, ytest = kennard_stone(X_data, Y_data, test_size=test_size)
      return xtrain, xtest, ytrain, ytest

def design_CNN_softmax(model, model_name):
  '''
  function: inputs number of CNN architecture layers to be defined and defines each layer
            with corresponding parameters. model is trained, compiled and saved in drive folder.
  param: d - d['list1'] = ['Conv2D', 'Activation', 'MaxPool2D', 'Flatten', 'Dense', 'Dropout']
             d['list2'] = [[16, 3, 1, 'same', 'relu'], ['relu'], [2, 2, 'same'], [], [64, 'relu'], [0.5]]
  returns: trained model, predictions
  '''

  img_size = 32
  channels = 3
  num_classes = 43
  layer_num = 1

  total_layers = int(input('Enter the total number of layers of the architecture:'))

  while (total_layers !=0):
    total_layers -= 1

    for i,add in enumerate(d['list1']):
      if add == 'Conv2D':

        if layer_num != 1:

            filters = d['list2'][i][0]
            kernel_size = tuple(d['list2'][i][1], d['list2'][i][1])
            strides = tuple(d['list2'][i][2], d['list2'][i][2])
            padding = d['list2'][i][3]
            activation = d['list2'][i][4]

            model.add(Conv2D(filters, kernel_size, strides, padding, activation = activation))
            layer_num += 1
          
        else:
            filters = int(input('Enter filter size: recommended-16, 32, 64, 128, 256, 512:'))
            kernel_size = tuple(map(int, input('Enter kernel size:').split(',')))
            strides = tuple(map(int, input('Enter strides:').split(',')))
            padding = str(input('Enter type of padding:'))
            activation = str(input('Enter the activation function:'))

            input_shape = (img_size, img_size, channels)
            model.add(Conv2D(filters, kernel_size, strides, padding, activation = activation, input_shape = input_shape))
            layer_num += 1

      elif add == 'MaxPool2D':
          pool_size = tuple(list2[i][0], list2[i][0])
          strides = tuple(list2[i][1], list2[i][1])
          padding = list2[i][2]

          model.add(MaxPool2D(pool_size, strides, padding))
          layer_num += 1

      elif add == 'Flatten': 
          model.add(Flatten())
          layer_num += 1

      elif add == 'Dense':
          units = list2[i][0]
          activation = list2[i][1]

          model.add(Dense(units, activation))
          layer_num += 1

      elif add == 'BatchNormalization': 
          model.add(BatchNormalization())
          layer_num += 1

      elif add == 'Dropout': 
          rate = list2[i][0]

          model.add(Dropout(rate = rate))
          layer_num += 1


  model.add(Flatten())
  model.add(Dense(512, activation='relu'))
  model.add(BatchNormalization())
  model.add(Dropout(rate=0.5))
  model.add(Dense(num_classes, activation='softmax'))

  print('Model architecture has been defined.')

  optimizer = str(input('Choose Optimizer:'))

  if optimizer in optimizers:
    if optimizer == 'SGD':

      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')

      if tuning == 'y':
        learning_rate = float(input('Enter learning rate:'))
        momentum = float(input('Enter momentum value:'))

        opt = keras.optimizers.SGD(learning_rate, momentum)

      else:
        opt = keras.optimizers.SGD()

    elif optimizer == 'RMSprop':

      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')

      if tuning == 'y':
        learning_rate = float(input('Enter learning rate:'))
        momentum = float(input('Enter momentum value:'))
        rho = float(input('Enter value:'))
        epsilon = float(input('Enter epsilon value:'))

        opt = keras.optimizers.RMSprop(learning_rate, rho, momentum, epsilon)
      else:
        opt = keras.optimizers.RMSprop()

    
    elif optimizer == 'Adam':
      tuning = input('Do you want to tune optimizer hyperparameters? (y/n)')

      if tuning == 'y':
        learning_rate = float(input('Enter learning rate:'))
        beta_1 = float(input('Enter beta_1 value:'))
        beta_2 = float(input('Enter beta_1 value:'))
        epsilon = float(input('Enter epsilon value:'))

        opt = keras.optimizers.Adam(learning_rate, beta_1, beta_2, epsilon=1e-07)

      else:
        opt = keras.optimizers.Adam()

  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

  X_train, Y_train = load_train_data()
  X_test, Y_test = load_test_data()
  batch_size = int(input('Enter batch size:'))
  epochs = int(input('Enter number of epochs:'))

  model.fit(X_train, Y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(X_test, Y_test),
            shuffle=True,)
  
  model.save(model_path+'/' + model_name + '.hdf5')
  predictions = model.evaluate(X_test, Y_test)

  return model, predictions